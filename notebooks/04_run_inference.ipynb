{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "34c9549b",
      "metadata": {
        "id": "34c9549b"
      },
      "source": [
        "# Etape 4 : Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a9d275",
      "metadata": {
        "id": "a2a9d275",
        "outputId": "a14f8729-c105-4dba-b186-1d628ffb9e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch OK : 2.9.1+cpu\n",
            "CUDA dispo ? False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Torch OK :\", torch.__version__)\n",
        "print(\"CUDA dispo ?\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728e8983",
      "metadata": {
        "id": "728e8983",
        "outputId": "5aab79fc-f8c8-41f7-86a5-f70507feb420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nouveau CWD = c:\\Users\\Simon VANDERCOILDEN\\Desktop\\Scolaire\\UTC\\IM05\\TX01\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Se placer √† la racine du repo (un niveau au-dessus de notebooks/)\n",
        "os.chdir(\"..\")\n",
        "print(\"Nouveau CWD =\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e006ec",
      "metadata": {
        "id": "b6e006ec",
        "outputId": "c5960ee2-3931-4231-c1d2-7dded99f6870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Chemins charg√©s :\n",
            "- VIDEO_CSV: data/splits/video_folds_5fold.csv\n",
            "- FRAMES_ROOT: data/frames/5_forstep1and2\n",
            "- SUPERIMG_CSV: data/splits/super_images_3x3_folds.csv\n",
            "- SUPERIMG_ROOT: data/super_images\n",
            "- FRAMEWISE_DIR: exp/results/framewise_resnet18\n",
            "- CONV_DIR: exp/results/super_images_convnext\n",
            "- TRES_DIR: exp/results/super_images_tresnetxl\n"
          ]
        }
      ],
      "source": [
        "# Chemins des fichiers\n",
        "VIDEO_CSV = \"data/splits/video_folds_5fold.csv\"\n",
        "FRAMES_ROOT = \"data/frames/5_forstep1and2\"\n",
        "SUPERIMG_CSV = \"data/splits/super_images_3x3_folds.csv\"\n",
        "SUPERIMG_ROOT = \"data/super_images\"\n",
        "\n",
        "# Dossiers des mod√®les entra√Æn√©s\n",
        "FRAMEWISE_DIR = \"exp/results/framewise_resnet18\"\n",
        "CONV_DIR = \"exp/results/super_images_convnext\"\n",
        "TRES_DIR = \"exp/results/super_images_tresnetxl\"\n",
        "\n",
        "print(\"üìÅ Chemins charg√©s :\")\n",
        "for name, val in {\n",
        "    \"VIDEO_CSV\": VIDEO_CSV,\n",
        "    \"FRAMES_ROOT\": FRAMES_ROOT,\n",
        "    \"SUPERIMG_CSV\": SUPERIMG_CSV,\n",
        "    \"SUPERIMG_ROOT\": SUPERIMG_ROOT,\n",
        "    \"FRAMEWISE_DIR\": FRAMEWISE_DIR,\n",
        "    \"CONV_DIR\": CONV_DIR,\n",
        "    \"TRES_DIR\": TRES_DIR,\n",
        "}.items():\n",
        "    print(f\"- {name}: {val}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8f21fe",
      "metadata": {
        "id": "bd8f21fe"
      },
      "outputs": [],
      "source": [
        "import subprocess, sys\n",
        "\n",
        "def run_python(script, args):\n",
        "    cmd = [sys.executable, script] + args\n",
        "    print(\"‚ñ∂Ô∏è Commande :\", \" \".join(cmd))\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "    if result.returncode != 0:\n",
        "        print(\"‚ùå ERREUR (code\", result.returncode, \")\")\n",
        "        print(result.stderr)\n",
        "    print(\"\\n--- FIN DU SCRIPT ---\\n\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97641744",
      "metadata": {
        "id": "97641744"
      },
      "source": [
        "## Inference framewise (5 folds) - Local CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d80ae75",
      "metadata": {
        "id": "2d80ae75",
        "outputId": "8f10e5b7-dc64-4091-af0f-e33c996a06ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "Fold 4 ‚Üí 1291 vid√©os\n",
            "Loading checkpoint: exp/results/framewise_resnet18/resnet18_fold4/best_model.pth\n",
            "Backbone: resnet18\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '25232', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23916_23', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '26985', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23921_9', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23917_12', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23906_10', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23921_11', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '25232', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23916_23', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '26985', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23921_9', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23917_12', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23906_10', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23921_11', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27661_1', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27627_2', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27664_3', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd22010', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd22584', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '26345_2', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd7235', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '25608', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27689_3', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27628_1', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27741', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '26439_3', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd15178', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27724', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '25551', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '26267_2', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27712_4', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd6473', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd3201', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd22772', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27675_2', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd23633', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd3183', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '26553_3', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o 'd16150', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '27675_5', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4782', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '977', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3528', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5129', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5261', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5135', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4721', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4800', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5206', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3531', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3153', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3521', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3520', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4795', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3550', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3462', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '1932', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3298', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5150', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4817', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3366', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '2289', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3195', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3191', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '2400', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '2000', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5215', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '2295', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '2522', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3482', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3337', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3538', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4793', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4783', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '2508', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3010', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4806', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3430', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3429', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3560', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '925', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3354', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5090', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4725', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4738', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4744', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3348', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3693', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '1972', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '2306', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '419', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4819', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3478', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '5142', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4740', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4784', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '3527', utilisation de frames noires dummy.\n",
            "[WARN] Aucune frame trouv√©e pour la vid√©o '4736', utilisation de frames noires dummy.\n",
            "\n",
            "Saved predictions ‚Üí exp/results/framewise_resnet18/preds_resnet18_fold4.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Inference:   0%|          | 0/81 [00:00<?, ?it/s]c:\\Users\\Simon VANDERCOILDEN\\Desktop\\Scolaire\\UTC\\IM05\\TX01\\qv-pipe-classifier\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\n",
            "Inference:   1%|          | 1/81 [00:47<1:03:08, 47.35s/it]\n",
            "Inference:   2%|‚ñè         | 2/81 [00:49<27:13, 20.67s/it]  \n",
            "Inference:   4%|‚ñé         | 3/81 [00:51<15:44, 12.11s/it]\n",
            "Inference:   5%|‚ñç         | 4/81 [00:53<10:21,  8.07s/it]\n",
            "Inference:   6%|‚ñå         | 5/81 [00:54<07:18,  5.77s/it]\n",
            "Inference:   7%|‚ñã         | 6/81 [00:56<05:32,  4.44s/it]\n",
            "Inference:   9%|‚ñä         | 7/81 [00:58<04:24,  3.57s/it]\n",
            "Inference:  10%|‚ñâ         | 8/81 [01:00<03:38,  3.00s/it]\n",
            "Inference:  11%|‚ñà         | 9/81 [01:01<03:07,  2.60s/it]\n",
            "Inference:  12%|‚ñà‚ñè        | 10/81 [01:03<02:48,  2.37s/it]\n",
            "Inference:  14%|‚ñà‚ñé        | 11/81 [01:05<02:35,  2.22s/it]\n",
            "Inference:  15%|‚ñà‚ñç        | 12/81 [01:07<02:21,  2.05s/it]\n",
            "Inference:  16%|‚ñà‚ñå        | 13/81 [01:09<02:14,  1.98s/it]\n",
            "Inference:  17%|‚ñà‚ñã        | 14/81 [01:10<02:05,  1.87s/it]\n",
            "Inference:  19%|‚ñà‚ñä        | 15/81 [01:12<01:59,  1.81s/it]\n",
            "Inference:  20%|‚ñà‚ñâ        | 16/81 [01:14<01:53,  1.75s/it]\n",
            "Inference:  21%|‚ñà‚ñà        | 17/81 [01:15<01:50,  1.72s/it]\n",
            "Inference:  22%|‚ñà‚ñà‚ñè       | 18/81 [01:17<01:45,  1.68s/it]\n",
            "Inference:  23%|‚ñà‚ñà‚ñé       | 19/81 [01:18<01:42,  1.66s/it]\n",
            "Inference:  25%|‚ñà‚ñà‚ñç       | 20/81 [01:20<01:40,  1.65s/it]\n",
            "Inference:  26%|‚ñà‚ñà‚ñå       | 21/81 [01:22<01:39,  1.66s/it]\n",
            "Inference:  27%|‚ñà‚ñà‚ñã       | 22/81 [01:23<01:37,  1.65s/it]\n",
            "Inference:  28%|‚ñà‚ñà‚ñä       | 23/81 [01:25<01:35,  1.65s/it]\n",
            "Inference:  30%|‚ñà‚ñà‚ñâ       | 24/81 [01:27<01:34,  1.65s/it]\n",
            "Inference:  31%|‚ñà‚ñà‚ñà       | 25/81 [01:28<01:32,  1.65s/it]\n",
            "Inference:  32%|‚ñà‚ñà‚ñà‚ñè      | 26/81 [01:30<01:30,  1.65s/it]\n",
            "Inference:  33%|‚ñà‚ñà‚ñà‚ñé      | 27/81 [01:32<01:28,  1.64s/it]\n",
            "Inference:  35%|‚ñà‚ñà‚ñà‚ñç      | 28/81 [01:33<01:27,  1.66s/it]\n",
            "Inference:  36%|‚ñà‚ñà‚ñà‚ñå      | 29/81 [01:35<01:26,  1.66s/it]\n",
            "Inference:  37%|‚ñà‚ñà‚ñà‚ñã      | 30/81 [01:37<01:26,  1.71s/it]\n",
            "Inference:  38%|‚ñà‚ñà‚ñà‚ñä      | 31/81 [01:39<01:28,  1.77s/it]\n",
            "Inference:  40%|‚ñà‚ñà‚ñà‚ñâ      | 32/81 [01:40<01:25,  1.74s/it]\n",
            "Inference:  41%|‚ñà‚ñà‚ñà‚ñà      | 33/81 [01:42<01:24,  1.75s/it]\n",
            "Inference:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 34/81 [01:44<01:23,  1.77s/it]\n",
            "Inference:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 35/81 [01:46<01:20,  1.75s/it]\n",
            "Inference:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 36/81 [01:47<01:17,  1.72s/it]\n",
            "Inference:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 37/81 [01:49<01:17,  1.76s/it]\n",
            "Inference:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 38/81 [01:51<01:17,  1.80s/it]\n",
            "Inference:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 39/81 [01:53<01:15,  1.79s/it]\n",
            "Inference:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 40/81 [01:55<01:12,  1.77s/it]\n",
            "Inference:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 41/81 [01:56<01:10,  1.76s/it]\n",
            "Inference:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 42/81 [01:58<01:08,  1.76s/it]\n",
            "Inference:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 43/81 [02:00<01:08,  1.79s/it]\n",
            "Inference:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 44/81 [02:02<01:05,  1.77s/it]\n",
            "Inference:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 45/81 [02:03<01:04,  1.80s/it]\n",
            "Inference:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 46/81 [02:05<01:02,  1.78s/it]\n",
            "Inference:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 47/81 [02:07<01:00,  1.78s/it]\n",
            "Inference:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 48/81 [02:09<00:59,  1.80s/it]\n",
            "Inference:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 49/81 [02:11<00:57,  1.79s/it]\n",
            "Inference:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 50/81 [02:12<00:55,  1.79s/it]\n",
            "Inference:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 51/81 [02:14<00:53,  1.78s/it]\n",
            "Inference:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 52/81 [02:16<00:53,  1.85s/it]\n",
            "Inference:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 53/81 [02:18<00:52,  1.87s/it]\n",
            "Inference:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 54/81 [02:20<00:49,  1.82s/it]\n",
            "Inference:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 55/81 [02:21<00:46,  1.77s/it]\n",
            "Inference:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 56/81 [02:23<00:46,  1.85s/it]\n",
            "Inference:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 57/81 [02:25<00:44,  1.83s/it]\n",
            "Inference:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 58/81 [02:27<00:40,  1.76s/it]\n",
            "Inference:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 59/81 [02:29<00:37,  1.73s/it]\n",
            "Inference:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 60/81 [02:30<00:35,  1.69s/it]\n",
            "Inference:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 61/81 [02:32<00:33,  1.67s/it]\n",
            "Inference:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 62/81 [02:33<00:31,  1.67s/it]\n",
            "Inference:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 63/81 [02:35<00:29,  1.65s/it]\n",
            "Inference:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 64/81 [02:37<00:27,  1.64s/it]\n",
            "Inference:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 65/81 [02:38<00:25,  1.60s/it]\n",
            "Inference:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 66/81 [02:40<00:24,  1.61s/it]\n",
            "Inference:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 67/81 [02:41<00:22,  1.59s/it]\n",
            "Inference:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 68/81 [02:43<00:20,  1.58s/it]\n",
            "Inference:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 69/81 [02:44<00:19,  1.59s/it]\n",
            "Inference:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 70/81 [02:46<00:17,  1.59s/it]\n",
            "Inference:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 71/81 [02:48<00:15,  1.59s/it]\n",
            "Inference:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 72/81 [02:49<00:14,  1.58s/it]\n",
            "Inference:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 73/81 [02:51<00:12,  1.54s/it]\n",
            "Inference:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 74/81 [02:52<00:10,  1.47s/it]\n",
            "Inference:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 75/81 [02:53<00:08,  1.46s/it]\n",
            "Inference:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 76/81 [02:55<00:07,  1.42s/it]\n",
            "Inference:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 77/81 [02:56<00:05,  1.38s/it]\n",
            "Inference:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 78/81 [02:57<00:04,  1.35s/it]\n",
            "Inference:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 79/81 [02:59<00:02,  1.34s/it]\n",
            "Inference:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 80/81 [03:00<00:01,  1.32s/it]\n",
            "Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [03:01<00:00,  1.20s/it]\n",
            "Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 81/81 [03:02<00:00,  2.25s/it]\n"
          ]
        }
      ],
      "source": [
        "!python src/infer/framewise_infer.py \\\n",
        "  --video_csv data/splits/video_folds_5fold.csv \\\n",
        "  --frames_root data/frames/5_forstep1and2 \\\n",
        "  --ckpt exp/results/framewise_resnet18/resnet18_fold4/best_model.pth \\\n",
        "  --fold 4 \\\n",
        "  --out exp/results/framewise_resnet18/preds_resnet18_fold4.npz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f8c1b89",
      "metadata": {
        "id": "3f8c1b89"
      },
      "source": [
        "## Inference ConvNeXt (5 folds) - Colab A100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "JN_RU4im7vhU",
        "outputId": "a43d580b-6969-44b2-cf6a-f8ec90a0144a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JN_RU4im7vhU",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clonage du d√©p√¥t dans /content (premi√®re fois dans cette session)\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/Simon-VDC/qv-pipe-classifier.git\n",
        "%cd qv-pipe-classifier\n",
        "\n",
        "!ls"
      ],
      "metadata": {
        "id": "ogmWt--X80I-",
        "outputId": "14f27ac9-9848-4d71-8972-4fff6eecf02a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ogmWt--X80I-",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'qv-pipe-classifier'...\n",
            "remote: Enumerating objects: 443, done.\u001b[K\n",
            "remote: Counting objects: 100% (275/275), done.\u001b[K\n",
            "remote: Compressing objects: 100% (235/235), done.\u001b[K\n",
            "remote: Total 443 (delta 139), reused 133 (delta 32), pack-reused 168 (from 1)\u001b[K\n",
            "Receiving objects: 100% (443/443), 1.21 MiB | 2.56 MiB/s, done.\n",
            "Resolving deltas: 100% (224/224), done.\n",
            "/content/qv-pipe-classifier\n",
            "CONFIG.md      docs\t\texp\t   project_tree.txt  requirements\n",
            "data\t       ENVIRONMENT.md\tLICENSE    README.md\t     scripts\n",
            "DATA_NOTES.md  environment.yml\tnotebooks  reports\t     src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext\"\n"
      ],
      "metadata": {
        "id": "rX4kVpCYBPDC"
      },
      "id": "rX4kVpCYBPDC",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boucle d'inf√©rence ConvNeXt pour les folds 0 √† 4\n",
        "for FOLD in range(5):\n",
        "    print(f\"=============== Fold {FOLD} ===============\")\n",
        "\n",
        "    cmd = f\"\"\"\n",
        "    python -m src.infer.superimages_infer \\\n",
        "        --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "        --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\" \\\n",
        "        --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold{FOLD}/best_model.pth\" \\\n",
        "        --fold       {FOLD} \\\n",
        "        --backbone   \"convnext_base\" \\\n",
        "        --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold{FOLD}.npz\" \\\n",
        "        --batch_size 4 \\\n",
        "        --image_size 1344\n",
        "    \"\"\"\n",
        "\n",
        "    print(cmd)\n",
        "    !$cmd"
      ],
      "metadata": {
        "id": "LG9ub_Ne7xIM",
        "outputId": "40492ecd-7ddc-409a-8519-f38169b10ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LG9ub_Ne7xIM",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Fold 0 ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth\"         --fold       0         --backbone   \"convnext_base\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold0.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 0 ‚Üí 578 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold0/best_model.pth\n",
            "Backbone utilis√© : convnext_base\n",
            "Inference: 100% 145/145 [01:14<00:00,  1.96it/s]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold0.npz\n",
            "=============== Fold 1 ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth\"         --fold       1         --backbone   \"convnext_base\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold1.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 1 ‚Üí 607 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold1/best_model.pth\n",
            "Backbone utilis√© : convnext_base\n",
            "Inference: 100% 152/152 [09:52<00:00,  3.90s/it]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold1.npz\n",
            "=============== Fold 2 ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth\"         --fold       2         --backbone   \"convnext_base\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold2.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 2 ‚Üí 557 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold2/best_model.pth\n",
            "Backbone utilis√© : convnext_base\n",
            "Inference: 100% 140/140 [09:01<00:00,  3.86s/it]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold2.npz\n",
            "=============== Fold 3 ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth\"         --fold       3         --backbone   \"convnext_base\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold3.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 3 ‚Üí 580 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold3/best_model.pth\n",
            "Backbone utilis√© : convnext_base\n",
            "Inference: 100% 145/145 [09:25<00:00,  3.90s/it]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold3.npz\n",
            "=============== Fold 4 ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth\"         --fold       4         --backbone   \"convnext_base\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold4.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 4 ‚Üí 559 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_convnext_cb_focal/convnext_base_fold4/best_model.pth\n",
            "Backbone utilis√© : convnext_base\n",
            "Inference: 100% 140/140 [09:11<00:00,  3.94s/it]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_convnext/preds_convnext_fold4.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2c109e",
      "metadata": {
        "id": "5d2c109e"
      },
      "source": [
        "## Inference TResNet-XL (5 folds) - Colab A100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©ation du dossier de sortie (si pas encore existant)\n",
        "!mkdir -p \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl\"\n",
        "\n",
        "# Boucle d'inf√©rence TResNet-XL pour les folds 0 √† 4\n",
        "for FOLD in range(5):\n",
        "    print(f\"=============== Fold {FOLD} (TResNet-XL) ===============\")\n",
        "\n",
        "    cmd = f\"\"\"\n",
        "    python -m src.infer.superimages_infer \\\n",
        "        --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\" \\\n",
        "        --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\" \\\n",
        "        --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold{FOLD}/best_model.pth\" \\\n",
        "        --fold       {FOLD} \\\n",
        "        --backbone   \"tresnet_xl.miil_in1k\" \\\n",
        "        --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold{FOLD}.npz\" \\\n",
        "        --batch_size 4 \\\n",
        "        --image_size 1344\n",
        "    \"\"\"\n",
        "\n",
        "    print(cmd)\n",
        "    !$cmd\n"
      ],
      "metadata": {
        "id": "7TkWXQrfCMLH",
        "outputId": "0858a3c2-7a92-411d-9cd2-2dd165cd4ac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7TkWXQrfCMLH",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Fold 0 (TResNet-XL) ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold0/best_model.pth\"         --fold       0         --backbone   \"tresnet_xl.miil_in1k\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold0.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 0 ‚Üí 578 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold0/best_model.pth\n",
            "Backbone utilis√© : tresnet_xl.miil_in1k\n",
            "Inference: 100% 145/145 [00:42<00:00,  3.44it/s]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold0.npz\n",
            "=============== Fold 1 (TResNet-XL) ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold1/best_model.pth\"         --fold       1         --backbone   \"tresnet_xl.miil_in1k\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold1.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 1 ‚Üí 607 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold1/best_model.pth\n",
            "Backbone utilis√© : tresnet_xl.miil_in1k\n",
            "Inference: 100% 152/152 [00:45<00:00,  3.35it/s]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold1.npz\n",
            "=============== Fold 2 (TResNet-XL) ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold2/best_model.pth\"         --fold       2         --backbone   \"tresnet_xl.miil_in1k\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold2.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 2 ‚Üí 557 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold2/best_model.pth\n",
            "Backbone utilis√© : tresnet_xl.miil_in1k\n",
            "Inference: 100% 140/140 [00:41<00:00,  3.41it/s]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold2.npz\n",
            "=============== Fold 3 (TResNet-XL) ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold3/best_model.pth\"         --fold       3         --backbone   \"tresnet_xl.miil_in1k\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold3.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 3 ‚Üí 580 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold3/best_model.pth\n",
            "Backbone utilis√© : tresnet_xl.miil_in1k\n",
            "Inference: 100% 145/145 [00:43<00:00,  3.36it/s]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold3.npz\n",
            "=============== Fold 4 (TResNet-XL) ===============\n",
            "\n",
            "    python -m src.infer.superimages_infer         --splits_csv \"/content/drive/MyDrive/QV Pipe/data/splits/super_images_3x3_folds_colab.csv\"         --img_root   \"/content/drive/MyDrive/QV Pipe/data/super_images\"         --ckpt       \"/content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold4/best_model.pth\"         --fold       4         --backbone   \"tresnet_xl.miil_in1k\"         --out        \"/content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold4.npz\"         --batch_size 4         --image_size 1344\n",
            "    \n",
            "Device: cuda\n",
            "Fold 4 ‚Üí 559 super-images\n",
            "Loading checkpoint: /content/drive/MyDrive/QV Pipe/models/super_images_tresnet_xl_cb_focal_highres/tresnet_xl.miil_in1k_fold4/best_model.pth\n",
            "Backbone utilis√© : tresnet_xl.miil_in1k\n",
            "Inference: 100% 140/140 [00:41<00:00,  3.37it/s]\n",
            "\n",
            "Saved predictions ‚Üí /content/drive/MyDrive/QV Pipe/exp/results/super_images_tresnetxl/preds_tresnetxl_fold4.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb76f910",
      "metadata": {
        "id": "cb76f910"
      },
      "source": [
        "## Ensemble final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d394c6",
      "metadata": {
        "id": "77d394c6",
        "outputId": "8638caaf-c130-4c6c-af16-efdc63dd668d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ñ∂Ô∏è Commande : c:\\Users\\Simon VANDERCOILDEN\\Desktop\\Scolaire\\UTC\\IM05\\TX01\\qv-pipe-classifier\\.venv\\Scripts\\python.exe src/infer/ensemble.py\n",
            "\n",
            "--- FIN DU SCRIPT ---\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['c:\\\\Users\\\\Simon VANDERCOILDEN\\\\Desktop\\\\Scolaire\\\\UTC\\\\IM05\\\\TX01\\\\qv-pipe-classifier\\\\.venv\\\\Scripts\\\\python.exe', 'src/infer/ensemble.py'], returncode=2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_python(\"src/infer/ensemble.py\", [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82728cfb",
      "metadata": {
        "id": "82728cfb",
        "outputId": "56d6480f-8d04-4468-9680-9cc80956a090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWD = c:\\Users\\Simon VANDERCOILDEN\\Desktop\\Scolaire\\UTC\\IM05\\TX01\\qv-pipe-classifier\\notebooks\n",
            "Framewise npz : []\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "\n",
        "print(\"CWD =\", os.getcwd())\n",
        "print(\"Framewise npz :\", glob.glob(\"exp/results/framewise_resnet18/*.npz\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25165157",
      "metadata": {
        "id": "25165157"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}